# ğŸ–ï¸ Gesture Controlled Mouse & Navigation Using Python + MediaPipe

## Control your entire computer using hand gestures in front of your webcam â€” no special hardware required!

This project uses:

- MediaPipe Hands (hand tracking)

- OpenCV (video input)

- PyAutoGUI (mouse + keyboard control)

- Real-time gesture recognition

- Drag & Drop, Scroll, Swipe, Right Click, etc.

# âœ¨ Features

âœ” Mouse Cursor Control (Index Finger Tracking)

âœ” Left Click (Thumb + Index Pinch)

âœ” Right Click (Thumb + Index + Middle Pinch)

âœ” Scroll (Index + Middle Up, Move Up/Down)

âœ” Drag & Drop (Pinch & Hold to Drag, Release to Drop)

âœ” Swipes Navigation

- Swipe Right â†’ Next Window (Alt+Tab)

- Swipe Left â†’ Previous Window (Shift+Alt+Tab)

- Swipe Up â†’ Task View

- Swipe Down â†’ Minimize All

âœ” Calibration System (Top & Bottom alignment)
âœ” Noise Filtering & Smoothing (Hybrid Kalman + EMA Filter)

No gloves, sensors, or depth cameras needed. Just a regular laptop webcam.

# ğŸ–¥ï¸ Demo (Gestures Overview)
| Gesture                    | Action                |
| -------------------------- | --------------------- |
| â˜ Index Up                 | Move Mouse            |
| ğŸ¤ Thumb + Index           | Left Click            |
| ğŸ¤ Thumb + Index + Middle  | Right Click           |
| âœŒ Index + Middle Up + Move | Scroll                |
| ğŸ¤ (Hold) â†’ Move           | Drag & Drop           |
| ğŸ– Swipe Right             | Next Window (Alt+Tab) |
| ğŸ– Swipe Left              | Previous Window       |
| ğŸ– Swipe Up                | Task View             |
| ğŸ– Swipe Down              | Minimize Windows      |

# ğŸ“¦ Dependencies

- Python 3.11.x recommended

- VSCode

- pip package manager

## Python Libraries
| Library         | Purpose                  |
| --------------- | ------------------------ |
| `opencv-python` | Webcam feed              |
| `mediapipe`     | Hand landmark detection  |
| `pyautogui`     | Mouse & keyboard control |
| `numpy`         | Math & filtering         |
| `time`          | Timing / debounce        |

# ğŸ› ï¸ Installation & Setup
1. Install Python 3.11

Download from:
 - https://www.python.org/downloads/

> âš  Make sure to check â€œAdd to PATHâ€ during installation.

# ğŸ§° VSCode Configuration Guide

### 1. Install VSCode

- https://code.visualstudio.com/

### 2. Install Extensions

Recommended extensions:

- Python (Microsoft)

- Pylance

- Code Runner (optional)

### 3. Clone this Repository
```bash
git clone https://github.com/<your-username>/<your-repo>.git
cd <your-repo>
```
### 4. Create a Virtual Environment (Recommended)

```bash
python -m venv .venv
```
Activate it:
```bash
.\.venv\Scripts\Activate.ps1
```
### 5. Install Requirements
```bash
pip install -r requirements.txt
```

If you donâ€™t have a requirements file, install manually:
```bash
pip install opencv-python mediapipe pyautogui numpy
```
### 6. Select Python Interpreter

Inside VSCode:
```bash
Ctrl + Shift + P â†’ "Python: Select Interpreter"
```

Choose:
```bash
./.venv/Scripts/python.exe
```
### 7. Enable Webcam Permissions (Windows)

Go to:
```
Settings â†’ Privacy â†’ Camera â†’ Allow desktop apps
```
> Make sure VSCode is allowed to use the camera.

# ğŸš€ Run the Program

Once dependencies are installed:
```bash
python main.py
```
Then follow calibration instructions:
```
1) Raise finger to TOP â†’ press SPACE
2) Lower finger to BOTTOM â†’ press SPACE
```
After calibration, mouse control starts!

# ğŸ“ Project Structure

### Example file structure:

```
gesture-mouse/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ gesture_utils.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .venv/                # optional virtual environment
```
# ğŸ“Œ Tips & Best Practices

- Use good lighting

- Keep hand centered

- Avoid overexposing background

- Laptop webcam works but external webcams give better FOV

# â— Known Limitations

- MediaPipe doesnâ€™t detect hands well if:

   - Background is too bright

   - Hand moves too far out of frame

   - Motion blur is high

- Gesture recognition depends on camera FOV & angle

#   ğŸ§© Future Improvements

- Hand pose ML model

- Gesture training mode

- Voice assistant integration

- Multi-hand support

- UI visual overlays

- BLE wearable for click depth

# ğŸ¤ Contributing

Pull requests are welcome!
If major changes are suggested, please open an issue first to discuss.

# ğŸ“œ License

MIT License â€” free for personal & commercial usage.
